import streamlit as st
import google.generativeai as genai
from duckduckgo_search import DDGS
import requests
from bs4 import BeautifulSoup
import re

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ÙˆØ§Ù„ÙˆØ§Ø¬Ù‡Ø© ---
st.set_page_config(page_title="Ù…Ø­ØªÙˆÙ‰ Ø¨Ø±Ùˆ", page_icon="ğŸš€", layout="wide")

# --- Ø¥Ø®ÙØ§Ø¡ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© ---
hide_streamlit_style = """
<style>
#MainMenu {visibility: hidden;}
footer {visibility: hidden;}
</style>
"""
st.markdown(hide_streamlit_style, unsafe_allow_html=True)

st.title("âœ¨ Ù…Ø­ØªÙˆÙ‰ Ø¨Ø±Ùˆ: Ù…Ø®Ø·Ø· Ø§Ù„Ù…Ù‚Ø§Ù„ ÙØ§Ø¦Ù‚ Ø§Ù„Ø³Ø±Ø¹Ø©")
st.write("Ø£Ø¯Ø®Ù„ ÙƒÙ„Ù…ØªÙƒ Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©ØŒ ÙˆØ¯Ø¹ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙŠØ­Ù„Ù„ **Ù‡ÙŠØ§ÙƒÙ„** Ø£ÙØ¶Ù„ Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ† ÙˆÙŠØ¨Ù†ÙŠ Ù„Ùƒ Ù…Ø®Ø·Ø· Ù…Ù‚Ø§Ù„ ÙŠØªÙÙˆÙ‚ Ø¹Ù„ÙŠÙ‡Ù….")

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø±Ù…Ø¬Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª (API) ---
try:
    GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
except (FileNotFoundError, KeyError):
    GEMINI_API_KEY = "AIzaSyAD2Rc1lOxzgj61DeVT5lV9qPJ4RVJ7V_s"  # <--- Ø¶Ø¹ Ù…ÙØªØ§Ø­Ùƒ Ù‡Ù†Ø§ Ù„Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù…Ø­Ù„ÙŠØ©

genai.configure(api_key=GEMINI_API_KEY)


# --- Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ---

@st.cache_data(ttl=3600)  # ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù„Ù…Ø¯Ø© Ø³Ø§Ø¹Ø© Ù„ØªØ³Ø±ÙŠØ¹ Ø§Ù„ØªØ¬Ø§Ø±Ø¨ Ø§Ù„Ù…ØªÙƒØ±Ø±Ø©
def get_competitor_links(keyword, num_results=5):
    """
    ØªØ¨Ø­Ø« Ø¹Ù† Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… DDGS Ù…Ø¹ Ø­ÙŠÙ„ Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.
    """
    links = []
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36'
    }
    try:
        with DDGS(headers=headers, timeout=20) as ddgs:
            results = list(ddgs.text(keywords=keyword, region='eg-ar', safesearch='off', max_results=num_results))
            if results:
                links = [r['href'] for r in results]
    except Exception as e:
        st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø­Ø«: {e}")
    return links


@st.cache_data(ttl=3600)
def scrape_headings_only(url):
    """
    (Ø§Ù„Ù‚Ù„Ø¨ Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ù„Ù„Ø£Ø¯Ø§Ø©)
    ÙŠØ³ØªØ®Ù„Øµ Ø¹Ù†Ø§ÙˆÙŠÙ† H2 Ùˆ H3 ÙÙ‚Ø· Ù…Ù† Ø±Ø§Ø¨Ø· Ø§Ù„Ù…Ù‚Ø§Ù„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… BeautifulSoup.
    """
    try:
        response = requests.get(url, timeout=10, headers={'User-Agent': 'Mozilla/5.0'})
        response.raise_for_status()
        soup = BeautifulSoup(response.content, 'html.parser')

        headings = []
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙƒÙ„ ÙˆØ³ÙˆÙ… h2 Ùˆ h3
        for heading in soup.find_all(['h2', 'h3']):
            # Ø¥Ø¶Ø§ÙØ© ## Ø£Ùˆ ### Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„ÙˆØ³Ù…
            prefix = "##" if heading.name == 'h2' else "###"
            headings.append(f"{prefix} {heading.get_text(strip=True)}")

        return "\n".join(headings)
    except Exception:
        return None


def generate_ultimate_outline_from_headings(keyword, competitor_headings):
    """
    (Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯)
    ÙŠÙ†Ø´Ø¦ Ù…Ø®Ø·Ø· Ø§Ù„Ù…Ù‚Ø§Ù„ Ø§Ù„Ø´Ø§Ù…Ù„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù‡ÙŠØ§ÙƒÙ„ Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ†.
    """
    content_prompt_part = ""
    for i, heading_list in enumerate(competitor_headings):
        content_prompt_part += f"**Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù…Ù‚Ø§Ù„ Ø§Ù„Ù…Ù†Ø§ÙØ³ {i + 1}:**\n{heading_list}\n\n---\n\n"

    prompt = f"""
    Ø£Ù†Øª Ø®Ø¨ÙŠØ± Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠ ÙÙŠ ØªØ­Ø³ÙŠÙ† Ù…Ø­Ø±ÙƒØ§Øª Ø§Ù„Ø¨Ø­Ø« (SEO) Ù…ØªØ®ØµØµ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰.
    Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØ© Ù‡ÙŠ: "{keyword}"
    Ù„Ù‚Ø¯ Ù‚Ù…Øª Ø¨ØªØ­Ù„ÙŠÙ„ **Ù‡ÙŠØ§ÙƒÙ„ Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª (Ù‚ÙˆØ§Ø¦Ù… Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† H2 Ùˆ H3)** Ù„Ø£ÙØ¶Ù„ Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ†ØŒ ÙˆÙ‡Ø°Ù‡ Ù‡ÙŠ:
    {content_prompt_part}
    Ù…Ù‡Ù…ØªÙƒ Ø§Ù„Ø¢Ù† Ù‡ÙŠ Ø§Ù„Ù‚ÙŠØ§Ù… Ø¨Ù…Ø§ ÙŠÙ„ÙŠ:
    1.  **ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‡ÙŠØ§ÙƒÙ„:** Ø­Ø¯Ø¯ Ø§Ù„Ø£Ù†Ù…Ø§Ø· ÙˆØ§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ø´ØªØ±ÙƒØ© Ø§Ù„ØªÙŠ ÙŠØºØ·ÙŠÙ‡Ø§ ÙƒÙ„ Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ† ÙÙŠ Ø¹Ù†Ø§ÙˆÙŠÙ†Ù‡Ù… Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© (H2s).
    2.  **ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ÙØ¬ÙˆØ© Ø§Ù„Ù‡ÙŠÙƒÙ„ÙŠØ©:** Ø§Ø¨Ø­Ø« Ø¹Ù† Ø²Ø§ÙˆÙŠØ© Ù…Ù‡Ù…Ø© Ø£Ùˆ Ù‚Ø³Ù… Ù…Ù†Ø·Ù‚ÙŠ (H2) Ù„Ù… ÙŠØ±ÙƒØ² Ø¹Ù„ÙŠÙ‡ Ø£ÙŠ Ù…Ù† Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ† ÙÙŠ Ù‡ÙŠÙƒÙ„ Ù…Ù‚Ø§Ù„Ù‡Ù….
    3.  **Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø´Ø§Ù…Ù„ (The Ultimate Outline):** Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø®Ø·Ø· Ù…Ù‚Ø§Ù„ Ù†Ù‡Ø§Ø¦ÙŠ (H2s Ùˆ H3s) Ø¨ØªÙ†Ø³ÙŠÙ‚ Markdown. ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ¯Ù…Ø¬ Ø§Ù„Ù…Ø®Ø·Ø· Ø£ÙØ¶Ù„ Ù…Ø§ ÙÙŠ Ù‡ÙŠØ§ÙƒÙ„ Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ† ÙˆÙŠØ¶ÙŠÙ Ù‚Ø³Ù…Ø§Ù‹ ÙØ±ÙŠØ¯Ø§Ù‹ ÙŠØºØ·ÙŠ Ø§Ù„ÙØ¬ÙˆØ© Ø§Ù„ØªÙŠ ÙˆØ¬Ø¯ØªÙ‡Ø§.
    Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯:
    - Ø§Ø³ØªØ®Ø¯Ù… `##` Ù„Ù€ H2 Ùˆ `###` Ù„Ù€ H3.
    - Ù„Ø§ ØªØ¶Ù Ø£ÙŠ Ù†ØµÙˆØµ Ø£Ùˆ Ø´Ø±ÙˆØ­Ø§Øª Ø®Ø§Ø±Ø¬ Ø§Ù„Ù…Ø®Ø·Ø·. Ø§Ø¨Ø¯Ø£ Ù…Ø¨Ø§Ø´Ø±Ø© Ø¨Ø£ÙˆÙ„ H2.
    - ÙƒÙ† Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Ù‹. Ø§Ù„Ù‡Ø¯Ù Ù‡Ùˆ Ø¨Ù†Ø§Ø¡ Ù‡ÙŠÙƒÙ„ Ù…Ù‚Ø§Ù„ ÙŠØªÙÙˆÙ‚ Ù…Ù†Ø·Ù‚ÙŠØ§Ù‹ Ø¹Ù„Ù‰ Ù‡ÙŠØ§ÙƒÙ„ Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ†.
    Ø§Ø¨Ø¯Ø£ Ø§Ù„Ø¢Ù†.
    """
    try:
        model = genai.GenerativeModel('models/gemini-pro-latest')
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ Google AI: {e}")
        return None


def display_expandable_outline(outline):
    """
    ØªØ¹Ø±Ø¶ Ø§Ù„Ù…Ø®Ø·Ø· Ø¨Ø´ÙƒÙ„ Ù‚Ø§Ø¨Ù„ Ù„Ù„Ø·ÙŠ (Expanders) Ù…Ø¹ ØªÙ„ÙˆÙŠÙ† Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ†.
    """
    st.subheader("ğŸ“ Ù…Ø®Ø·Ø· Ø§Ù„Ù…Ù‚Ø§Ù„ Ø§Ù„Ù…Ù‚ØªØ±Ø­:")
    parts = re.split(r'(?=^##\s)', outline, flags=re.MULTILINE)
    for part in parts:
        if not part.strip():
            continue
        lines = part.strip().split('\n')
        h2_title = lines[0].strip('# ').strip()
        with st.expander(f"**{h2_title}**"):
            st.markdown(f'<h2 style="color: #0068c9; font-size: 1.5em;">{h2_title}</h2>', unsafe_allow_html=True)
            for line in lines[1:]:
                if line.strip().startswith('###'):
                    h3_title = line.strip('# ').strip()
                    st.markdown(f'<h3 style="color: #555555; font-size: 1.1em; margin-left: 20px;">- {h3_title}</h3>',
                                unsafe_allow_html=True)
                elif line.strip():
                    st.markdown(f'<p style="margin-left: 20px;">{line.strip()}</p>', unsafe_allow_html=True)


# --- ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ---
keyword = st.text_input("Ø£Ø¯Ø®Ù„ Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù‡Ù†Ø§:", placeholder="Ù…Ø«Ø§Ù„: Ø£ÙØ¶Ù„ Ø·Ø±Ù‚ Ø§Ù„ØªØ³ÙˆÙŠÙ‚ Ø§Ù„Ø±Ù‚Ù…ÙŠ")

if st.button("ğŸš€ Ø­Ù„Ù„ Ù‡ÙŠØ§ÙƒÙ„ Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ† ÙˆØ§Ø¨Ù†Ù Ø§Ù„Ù…Ø®Ø·Ø·", type="primary"):
    if not keyword:
        st.warning("ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ ÙƒÙ„Ù…Ø© Ù…ÙØªØ§Ø­ÙŠØ© Ø£ÙˆÙ„Ø§Ù‹.")
    elif not GEMINI_API_KEY or GEMINI_API_KEY == "YOUR_API_KEY":
        st.error("ÙŠØ±Ø¬Ù‰ ÙˆØ¶Ø¹ Ù…ÙØªØ§Ø­ Google AI API Ø§Ù„ØµØ­ÙŠØ­ ÙÙŠ Ø§Ù„ÙƒÙˆØ¯ Ø£ÙˆÙ„Ø§Ù‹.")
    else:
        with st.spinner("Ø§Ù„Ø®Ø·ÙˆØ© 1/3: Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£ÙØ¶Ù„ Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ†..."):
            links = get_competitor_links(keyword, num_results=5)

        if not links:
            st.error("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù†Ø§ÙØ³ÙŠÙ†. Ø­Ø§ÙˆÙ„ Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙƒÙ„Ù…Ø© Ù…ÙØªØ§Ø­ÙŠØ© Ù…Ø®ØªÙ„ÙØ©.")
        else:
            st.info(f"ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(links)} Ù…Ù†Ø§ÙØ³ÙŠÙ†. Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ù‡ÙŠØ§ÙƒÙ„Ù‡Ù…...")

            competitor_headings = []
            with st.spinner("Ø§Ù„Ø®Ø·ÙˆØ© 2/3: Ø§Ø³ØªØ®Ù„Ø§Øµ Ù‡ÙŠØ§ÙƒÙ„ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† (H2, H3)... (ÙØ§Ø¦Ù‚ Ø§Ù„Ø³Ø±Ø¹Ø©!)"):
                for link in links[:3]:
                    headings = scrape_headings_only(link)
                    if headings:
                        competitor_headings.append(headings)

            if not competitor_headings:
                st.error("ÙØ´Ù„ Ø§Ø³ØªØ®Ù„Ø§Øµ Ù‡ÙŠØ§ÙƒÙ„ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† Ù…Ù† Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ†.")
            else:
                with st.spinner("Ø§Ù„Ø®Ø·ÙˆØ© 3/3: Ø§Ù„Ø¹Ù‚Ù„ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠ (Gemini) ÙŠØ¨Ù†ÙŠ Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø´Ø§Ù…Ù„..."):
                    ultimate_outline = generate_ultimate_outline_from_headings(keyword, competitor_headings)

                st.success("ğŸ‰ ØªÙ… Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø´Ø§Ù…Ù„ Ø¨Ù†Ø¬Ø§Ø­!")
                st.markdown("---")

                if ultimate_outline:
                    display_expandable_outline(ultimate_outline)
                else:
                    st.error("ÙØ´Ù„ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù‡ÙŠÙƒÙ„.")
